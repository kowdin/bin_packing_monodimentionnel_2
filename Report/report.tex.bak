\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{xcolor}

\let\oldproof\proof
\renewcommand{\proof}{\color{gray}\oldproof}


\title{Continuous optimization}
\author{Samuel Buchet \& Dorian Dumez \& Brendan Guevel}
\date{Mai 2017}

\begin{document}

\maketitle

\section{Relaxation continue}


\subsection{Problème de base}

On peut écrire le problème de bin-packing monodimensionnel comme :\\
$\text{(PE) : min } z = \sum \limits_{b = 1 }^{n} u_b$\\
s.c.
\begin{align*}
 \forall b \in [\![ 1 , n ]\!] : \sum \limits_{p = 1}^{n} s_p x_{pb} \leqslant u_b c \text{ (1)}\\
 \forall p \in [\![ 1 , n ]\!] : \sum \limits_{b = 1}^{n} x_{pb} = 1 \text{ (2)}\\
 \forall p \in [\![ 1 , n ]\!] : \forall b \in [\![ 1 , n ]\!] : u_b , x_{pb} \in \{0,1\}
\end{align*}
Avec pour paramètre :
\begin{itemize}
\item
$n$, le nombre d'objet, donc un majorant du nombre de bin nécessaire
\item
$c$, la capacité d'une boite
\item
$s$, le vecteur de la taille des objets
\end{itemize}
Et pour variable :
\begin{itemize}
\item
$u_b$ qui est vrai si on utilise le bin numéro $b$
\item
$x_{pb}$ qui est vrai si on met l'objet $p$ dans le bin $b$
\end{itemize}
Bien que juste ce programme linéaire n'est pas très utilisable en pratique, en effet :
\begin{itemize}
\item
il ne prend pas en compte la redondance des objets, si on a 100 fois le même objet il créera 100 variables
\item
bien qu'identique de part leur caractéristique tous les bin sont différencié
\end{itemize}
Donc il en résultera un nombre considérable de solution équivalente due à des symétries. Un algorithme de résolution devrai donc prendre en compte l’interprétation du problème ou y ajouter des contraintes comme : 
\begin{align*}
 \forall b \in [\![ 1 , n-1 ]\!] : u_b \geqslant u_{b+1} \text{ (3)}\\
 \forall b \in [\![ 1 , n-1 ]\!] : argmin_{ p \in \{ i \in [\![ 1 , n ]\!] | x_{ib} = 1 \} } p \leqslant argmin_{ p \in \{ i \in [\![ 1 , n ]\!] | x_{i,b+1} = 1 \} } p \text{ (4)}
\end{align*}
Où la contraintes (3) force les bin ouvert à être ceux avec les plus petit identifiant et la (4) ordonne les bin par le schéma d'objet qu'il contient. Mais même si cela ne règle pas le problème des variables redondante, et rend ce problème nécessaire par leur utilisation.

\subsection{Relaxation linéaire}

La relaxation linéaire de (PE) s'écrit :\\
$\text{(Rl) : min } z_{\text{Rl}} = \sum \limits_{b = 1 }^{n} u_b$\\
s.c.
\begin{align*}
 \forall b \in [\![ 1 , n ]\!] : \sum \limits_{p = 1}^{n} s_p x_{pb} \leqslant u_b c \text{ (1)}\\
 \forall p \in [\![ 1 , n ]\!] : \sum \limits_{b = 1}^{n} x_{pb} = 1 \text{ (2)}\\
 \forall p \in [\![ 1 , n ]\!] : \forall b \in [\![ 1 , n ]\!] : u_b , x_{pb} \in [0,1]
\end{align*}
Mais on peut alors toujours dire que la valeur de la relaxation linéaire est $\frac{\sum \limits_{p = 1}^n s_p}{c}$. Sauf que la valeur de (PE) est toujours entière donc on peut utiliser comme borne inférieure $\Bigl\lceil\dfrac{\sum \limits_{p = 1}^n s_p}{c}\Bigr\rceil\qquad$

\begin{proof}
Soit $u^*_b$ et $x^*_{bp}$ la valeur des variables dans la solution optimale de la relaxation linéaire. Alors on a bien évidement $\forall p \in [\![ 1 , n ]\!] : \sum \limits_{b = 1}^{n} x^*_{pb} = 1$ par la contrainte (2). De plus, vu que chaque $u_b$ n’apparais que dans une contrainte, on peut dire que $u^*_b = \frac{\sum \limits_{p=1}^n s_p x^*_{pb}}{c}$ par la contrainte (1). La valeur cette solution est alors $\sum \limits_{b = 1}^n  \frac{\sum \limits_{p=1}^n s_p x^*_{pb}}{c} = \frac{\sum \limits_{p = 1}^n s_p}{c}$ par la contrainte (2).\\
\end{proof}

\section{tâches}

\begin{itemize}
    \item réaliser un parseur $\Rightarrow$ OK
    \item faire la relaxation continue
    \item heuristique pour borne supérieure (best fit) $\Rightarrow$ OK
    \item relaxation lagrangienne + réparation
    \item tests statistiques
\end{itemize}
~\\
Pour l'heuristique lagrangienne :
\begin{itemize}
    \item choisir les contraintes à dualiser
    \item trouver un moyen de résoudre le problème relâché
    \item mettre en oeuvre l'algorithme de descente de gradient
    \item créer une heuristique de réparation
\end{itemize}

\section{Relaxations lagrangiennes possibles}

\subsection{Dualisation de la contrainte 1}
Premièrement on remarque que l'on peut séparer en deux la contrainte (1) et donc écrire (PE) comme : \\
$\text{(PE) : min } z = \sum \limits_{b = 1 }^{n} u_b$\\
s.c.
\begin{align*}
 \forall b \in [\![ 1 , n ]\!] : \sum \limits_{p = 1}^{n} s_p x_{pb} \leqslant c \text{ (1')}\\
 \forall p \in [\![ 1 , n ]\!] : \forall b \in [\![ 1 , n ]\!] : x_{pb} \leqslant u_b \text{ (1'')}\\
 \forall p \in [\![ 1 , n ]\!] : \sum \limits_{b = 1}^{n} x_{pb} = 1 \text{ (2)}\\
 \forall p \in [\![ 1 , n ]\!] : \forall b \in [\![ 1 , n ]\!] : u_b , x_{pb} \in \{0,1\}
\end{align*}

Alors si on dualise la contrainte $(1')$ on obtient :\\
$RL_1(u) \text{ : min } z_1(u) = \sum \limits_{b = 1}^{n} u_b - \mu_b (c - \sum \limits_{p = 1}^{n} s_p x_{pb} )$\\
s.c.
\begin{align*}
 \forall p \in [\![ 1 , n ]\!] : \forall b \in [\![ 1 , n ]\!] : x_{pb} \leqslant u_b \text{ (1'')}\\
 \forall p \in [\![ 1 , n ]\!] : \sum \limits_{b = 1}^{n} x_{pb} = 1 \text{ (2)}\\
 \forall p \in [\![ 1 , n ]\!] : \forall b \in [\![ 1 , n ]\!] : u_b , x_{pb} \in \{0,1\}
\end{align*}
Où $\mu \geqslant 0$ car la contrainte $(1')$ est une contrainte en inégalité.\\

En écrivant la fonction objectif comme  $\text{ : min } z_1(u) = \sum \limits_{b = 1}^{n}( u_b + \sum \limits_{p = 1}^n (\mu_b s_p x_{pb})) - \sum \limits_{b = 1}^{n} \mu_b c$. On peut alors voir $RL_1(u)$ comme un problème d'UFLP (uncapacited facility location problem) avec des coûts d'ouverture de 1 et des coûts d'association de $\mu_b s_p$. A noter que l'on ajoute un terme constant à la fonction objectif pour obtenir la vraie valeur de la relaxation lagrangienne.

\subsection{Dualisation de la contrainte 2}

Si on dualise la contrainte 2, que l'on pourrait appeler "tout objet", on obtient :\\
$RL_2(u) \text{ : min } z_2(u) = \sum \limits_{b = 1}^{n} u_b + \sum \limits_{p = 1}^{n} \mu_p (1 - \sum \limits_{b = 1}^{n} x_{pb})$\\
s.c.
\begin{align*}
 \forall b \in [\![ 1 , n ]\!] : \sum \limits_{p = 1}^{n} s_p x_{pb} \leqslant u_b c \text{ (1)}\\
 \forall p \in [\![ 1 , n ]\!] : \forall b \in [\![ 1 , n ]\!] : x_{pb}, u_b \in \{0,1\}
\end{align*}
Mais vu que la contrainte 2 est une contrainte d'égalité le signe de $\mu$ est libre.

On peut réécrire la fonction objectif comme $\text{min } z_2(u) =  \sum \limits_{b = 1}^{n} \left( u_b - \sum \limits_{p = 1}^{n} \mu_p x_{pb} \right) + \sum \limits_{p = 1}^{n} \mu_p$. De plus si $u_b = 1$ la contrainte (1) est une contrainte de capacité. On peut donc résoudre $RL_2(u)$ en résolvant n problème de knapsack où les objets ont comme valeur $- \mu_p$, puis en mettant le $u_b$ correspondant au problème résolut à 1 si la valeur de la solution optimale est supérieur à $-1$. A noter qu'après avoir résolut nos n 01KP et déterminé la valeur des $u_b$ il faudra y ajouter la somme des $\mu_p$ pour avoir la valeur de la relaxation lagrangienne.

\section{Python}

Un peu de doc bien faite : \url{https://www.tutorialspoint.com/python/index.htm} \newline

Pour exécuter le code : python3 bin\_packing.py

\end{document}
